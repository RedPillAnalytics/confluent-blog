{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting our Docker Environment\n",
    "### We even use Gradle to manage Docker using `com.avast.gradle.docker-compose` plugin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./gradlew --console=plain tasks --group docker -q\n",
    "!./gradlew --console=plain -q composeUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Python to interact with KSQL. Let's see if `CLICKSTREAM`, `CLICKSTREAM_CODES` and `CLIICKSTREAM_USERS` are there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksql = \"/usr/local/bin/ksql\"\n",
    "!echo \"LIST TOPICS;\" | \"$ksql\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Developer Experience\n",
    "### Create a *registration* stream `CLICKSTREAM`. This is sort of like DDL in relational DBs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = (\n",
    "    \"CREATE STREAM clickstream \"\n",
    "    \"(_time bigint, time varchar, ip varchar, request varchar, status int, userid int, bytes bigint, agent varchar) \"\n",
    "    \"with (kafka_topic = 'clickstream', value_format = 'json');\"\n",
    ")\n",
    "!echo \"$sql\" | \"$ksql\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create *persistent query* table `EVENTS_PER_MIN`, which reads data from `CLICKSTREAM` and initializes the streaming process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = (\n",
    "    \"CREATE TABLE events_per_min AS SELECT userid, count(*) AS events \"\n",
    "    \"FROM clickstream window \"\n",
    "    \"TUMBLING (size 60 second) GROUP BY userid;\"\n",
    ")\n",
    "!echo \"$sql\" | \"$ksql\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppose we want to make changes to `CLICKSTREAM`. Just drop it right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = (\n",
    "    \"DROP STREAM clickstream; \"\n",
    ")\n",
    "!echo \"$sql\" | \"$ksql\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bummer. First we need to terminate the persistent query... but the *query id* is auto-incrementing, and not constant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = (\n",
    "    \"TERMINATE QUERY CTAS_EVENTS_PER_MIN_0; \"\n",
    ")\n",
    "!echo \"$sql\" | \"$ksql\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now drop CLICKSTREAM again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = (\n",
    "    \"DROP STREAM clickstream; \"\n",
    ")\n",
    "!echo \"$sql\" | \"$ksql\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can do something better to increase developer efficiency!\n",
    "\n",
    "# The `gradle-confluent` Plugin\n",
    "\n",
    "### [GitHub Repository](https://github.com/RedPillAnalytics/gradle-confluent)\n",
    "\n",
    "### [Gradle Plugin Portal](https://plugins.gradle.org/plugin/com.redpillanalytics.gradle-confluent)\n",
    "\n",
    "### Our `build.gradle` file:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plugins {\n",
    "   id \"com.redpillanalytics.gradle-confluent\" version '1.1.8'\n",
    "}\n",
    "\n",
    "confluent {\n",
    "    enablePipelines true\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at the Gradle tasks available by applying the plugin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./gradlew ksql:tasks --group confluent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see the *help* assocated with the `pipelineExecute` task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./gradlew help --task ksql:pipelineExecute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at our [pipeline source code](https://github.com/RedPillAnalytics/kafka-examples/tree/master/ksql/src/main/pipeline).\n",
    "\n",
    "### Used to execute a single pipeline. Notice the plugin auto-generates `TERMINATE` and `DROP` statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./gradlew --console=plain ksql:pipelineExecute --pipeline-dir 01-clickstream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or multiple pipelines. We'll turn the logging up a bit. The `DROP` statements occur in reverse order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./gradlew --console=plain ksql:pipelineExecute -i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `pipelineExecute` task is great for developers. But in a real delivery pipeline, we want to build and publish artifacts. We are using mavenLocal() which defaults to `$HOME/.m2` as our maven repository location:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plugins {\n",
    "   id \"com.redpillanalytics.gradle-confluent\" version \"1.1.8\"\n",
    "   id 'maven-publish'\n",
    "}\n",
    "\n",
    "publishing {\n",
    "    repositories {\n",
    "        mavenLocal()\n",
    "    }\n",
    "}\n",
    "group = 'com.redpillanalytics'\n",
    "version = '1.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./gradlew --console=plain ksql:build ksql:publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zipinfo ~/.m2/repository/com/redpillanalytics/ksql-pipeline/1.0.0/ksql-pipeline-1.0.0.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We build the `ksql-script.sql` script in case we want to use it as our queries file, with either option `--queries-file` or, with property `ksql.queries.file`. Notice we *normalize* the script, removing comments, line breaks, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ksql/build/pipeline/ksql-script.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We chose to deploy our artifacts using the KSQL REST API, which is similar to using the `pipelineExecute` command, but extracts and executes scripts in the artifact instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./gradlew --console=plain ksql:deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, with `-i` for more info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./gradlew --console=plain ksql:deploy -i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We realized quickly that we needed to be able to granularly control some of our auto-generated KSQL. For instance... we wanted to control whether `DELETE TOPIC` was added to `DROP` statements. So we introduced *directives*:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--@DeleteTopic\n",
    "CREATE TABLE ENRICHED_ERROR_CODES_COUNT AS\n",
    "SELECT code, definition, COUNT(*) AS count\n",
    "FROM ENRICHED_ERROR_CODES WINDOW TUMBLING (size 30 second)\n",
    "GROUP BY code, definition\n",
    "HAVING COUNT(*) > 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directives are *smart comments* beginning with `--@`. So far we have only introduced `--@DeleteTopic`, but others are planned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./gradlew --console=plain ksql:pipelineExecute --pipeline-dir 01-clickstream -i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KSQL User Defined Functions\n",
    "\n",
    "### What we really needed was a `CASE` statement. KSQL doesn't have the [CASE](https://github.com/confluentinc/ksql/issues/620) yet, but it's coming.\n",
    "\n",
    "### In the meantime, we wrote the `decode()` function, which was inspired by the Oracle `decode()` function that existed before `CASE`.\n",
    "\n",
    "### `Decode` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```groovy\n",
    "import groovy.util.logging.Slf4j\n",
    "import io.confluent.ksql.function.udf.Udf\n",
    "import io.confluent.ksql.function.udf.UdfDescription\n",
    "\n",
    "@Slf4j\n",
    "@UdfDescription(\n",
    "        name = \"decode\",\n",
    "        description = \"\"\"Given up to 3 pairs of 'search' and 'text', return the first 'text' value where 'search' matches 'expression'. If no match, return 'defaultvalue'. 'ignorecase' defaults to 'false'.\"\"\")\n",
    "class Decode {\n",
    "\n",
    "   @Udf(description = \"\"\"Given 1 pair of 'search' and 'text', return the first 'text' value where 'search' matches 'expression'. If no match, return 'defaultvalue'. 'ignorecase' defaults to 'false'.\"\"\")\n",
    "   String decode(String expression, String search1, String text1, String defaultvalue, Boolean ignorecase = false) {\n",
    "\n",
    "      // If any of the expected values are null, then just return null\n",
    "      if (expression == null || search1 == null || text1 == null) return null\n",
    "\n",
    "      return Utils.textMatch(expression, search1, ignorecase) ? text1 : defaultvalue\n",
    "   }\n",
    "    \n",
    "   @Udf(description = \"\"\"Given 2 pairs of 'search' and 'text', return the first 'text' value where 'search' matches 'expression'. If no match, return 'defaultvalue'. 'ignorecase' defaults to 'false'.\"\"\")\n",
    "   String decode(String expression, String search1, String text1, String search2, String text2, String defaultvalue, Boolean ignorecase = false) {\n",
    "\n",
    "      // If any of the expected values are null, then just return null\n",
    "      if (expression == null || search1 == null || text1 == null || search2 == null || text2 == null) return null\n",
    "\n",
    "      if (Utils.textMatch(expression, search1, ignorecase)) return text1\n",
    "\n",
    "      else if (Utils.textMatch(expression, search2, ignorecase)) return text2\n",
    "\n",
    "      else return defaultvalue\n",
    "   }\n",
    "    \n",
    "   @Udf(description = \"\"\"Given 3 pairs of 'search' and 'text', return the first 'text' value where 'search' matches 'expression'. If no match, return 'defaultvalue'. 'ignorecase' defaults to 'false'.\"\"\")\n",
    "   String decode(String expression, String search1, String text1, String search2, String text2, String search3, String text3, String defaultvalue, Boolean ignorecase = false) {\n",
    "\n",
    "      // If any of the expected values are null, then just return null\n",
    "      if (expression == null || search1 == null || text1 == null || search2 == null || text2 == null || search3 == null || text3 == null) return null\n",
    "\n",
    "      if (Utils.textMatch(expression, search1, ignorecase)) return text1\n",
    "\n",
    "      else if (Utils.textMatch(expression, search2, ignorecase)) return text2\n",
    "\n",
    "      else if (Utils.textMatch(expression, search3, ignorecase)) return text3\n",
    "\n",
    "      else return defaultvalue\n",
    "   }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DecodeTest` Spock test specification:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```groovy\n",
    "import groovy.util.logging.Slf4j\n",
    "import spock.lang.Shared\n",
    "import spock.lang.Specification\n",
    "import spock.lang.Unroll\n",
    "\n",
    "@Slf4j\n",
    "class DecodeTest extends Specification {\n",
    "\n",
    "   @Shared\n",
    "   Decode decode = new Decode()\n",
    "\n",
    "   @Unroll\n",
    "   def \"When: #expression, #search, #text, #defaultValue; Expect: #result\"() {\n",
    "\n",
    "      expect:\n",
    "      decode.decode(expression, search, text, defaultValue) == result\n",
    "\n",
    "      where:\n",
    "      expression    | search        | text  | defaultValue || result\n",
    "      'KSQL Rocks!' | 'ksql rocks!' | 'yes' | 'no'         || 'no'\n",
    "      'KSQL Rocks!' | 'KSQL Rocks!' | 'yes' | 'no'         || 'yes'\n",
    "   }\n",
    "\n",
    "   @Unroll\n",
    "   def \"When: #expression, #search, #text, #defaultValue, #ignorecase; Expect: #result\"() {\n",
    "\n",
    "      expect:\n",
    "      decode.decode(expression, search, text, defaultValue, ignorecase) == result\n",
    "\n",
    "      where:\n",
    "      expression    | search        | text  | defaultValue | ignorecase || result\n",
    "      'KSQL Rocks!' | 'KSQL rocks!' | 'yes' | 'no'         | true       || 'yes'\n",
    "      'KSQL Rocks!' | 'KSQL Rocks!' | 'yes' | 'no'         | true       || 'yes'\n",
    "      'KSQL Rocks!' | 'KSQL rocks!' | 'yes' | 'no'         | false      || 'no'\n",
    "   }\n",
    "\n",
    "   @Unroll\n",
    "   def \"When: #expression, #search1, #text1, #search2, #text2, #defaultValue, #ignorecase; Expect: #result\"() {\n",
    "\n",
    "      expect:\n",
    "      decode.decode(expression, search1, text1, search2, text2, defaultValue, ignorecase) == result\n",
    "\n",
    "      where:\n",
    "      expression    | search1       | text1 | search2       | text2 | defaultValue | ignorecase || result\n",
    "      'KSQL Rocks!' | 'KSQL rocks!' | 'yes' | 'KSQL Sucks!' | 'no'  | 'no'         | true       || 'yes'\n",
    "      'KSQL Rocks!' | 'KSQL rocks!' | 'no'  | 'KSQL Rocks!' | 'yes' | 'no'         | false      || 'yes'\n",
    "      'KSQL Rocks!' | 'KSQL rocks!' | 'no'  | 'KSQL Sucks!' | 'no'  | 'yes'        | false      || 'yes'\n",
    "   }\n",
    "\n",
    "   @Unroll\n",
    "   def \"When: #expression, #search1, #text1, #search2, #text2, #search3, #text3, #defaultValue, #ignorecase; Expect: #result\"() {\n",
    "\n",
    "      expect:\n",
    "      decode.decode(expression, search1, text1, search2, text2, search3, text3, defaultValue, ignorecase) == result\n",
    "\n",
    "      where:\n",
    "      expression    | search1       | text1 | search2       | text2 | search3       | text3 | defaultValue | ignorecase || result\n",
    "      'KSQL Rocks!' | 'KSQL rocks!' | 'yes' | 'KSQL Sucks!' | 'no'  | 'KSQL, meh'   | 'no'  | 'no'         | true       || 'yes'\n",
    "      'KSQL Rocks!' | 'KSQL rocks!' | 'no'  | 'KSQL Rocks!' | 'yes' | 'KSQL, meh'   | 'no'  | 'no'         | false      || 'yes'\n",
    "      'KSQL, meh'   | 'KSQL rocks!' | 'no'  | 'KSQL Sucks!' | 'no'  | 'KSQL, meh'   | 'yes' | 'no'         | false      || 'yes'\n",
    "      'KSQL, meh'   | 'KSQL rocks!' | 'no'  | 'KSQL Sucks!' | 'no'  | \"What's KSQL\" | 'no'  | 'yes'        | false      || 'yes'\n",
    "      'KSQL, meh'   | 'ksql rocks!' | 'no'  | 'ksql, meh'   | 'yes' | \"What's KSQL\" | 'no'  | 'no'         | true       || 'yes'\n",
    "\n",
    "   }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And here is our `build.gradle` file for the `functions` subproject:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plugins {\n",
    "   id 'groovy'\n",
    "   id 'maven-publish'\n",
    "   id 'com.adarshr.test-logger' version '1.6.0'\n",
    "   id \"com.github.johnrengelman.shadow\" version \"5.0.0\"\n",
    "}\n",
    "\n",
    "//customize ShadowJar\n",
    "jar.enabled = false\n",
    "shadowJar { classifier = '' }\n",
    "tasks.build.dependsOn tasks.shadowJar\n",
    "\n",
    "// mavenLocal publish\n",
    "publishing {\n",
    "   publications {\n",
    "      shadow(MavenPublication) { publication ->\n",
    "         project.shadow.component(publication)\n",
    "      }\n",
    "   }\n",
    "   repositories {\n",
    "      mavenLocal()\n",
    "   }\n",
    "}\n",
    "group = 'com.redpillanalytics'\n",
    "version = '1.0.0'\n",
    "\n",
    "dependencies {\n",
    "   compile localGroovy()\n",
    "   compile 'org.slf4j:slf4j-simple:+'\n",
    "   compile 'io.confluent.ksql:ksql-udf:+'\n",
    "   testCompile 'org.spockframework:spock-core:1.2-groovy-2.5'\n",
    "}\n",
    "\n",
    "// confluent dependencies\n",
    "repositories {\n",
    "   jcenter()\n",
    "   maven {\n",
    "      url \"http://packages.confluent.io/maven/\"\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build and publish our UDF artifact, and see how many items are in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./gradlew --console=plain functions:build functions:publish\n",
    "!zipinfo -h ~/.m2/repository/com/redpillanalytics/functions/1.0.0/functions-1.0.0.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/usr/local/bin/docker cp ~/.m2/repository/com/redpillanalytics/functions/1.0.0/functions-1.0.0.jar ksql-server:/etc/ksql-server/ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"DESCRIBE FUNCTION DECODE;\" | \"$ksql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = (\n",
    "    \"select definition, decode(definition, \"\n",
    "    \"'Proxy authentication required','Bad', \"\n",
    "    \"'Page not found','Bad', \"\n",
    "    \"'Redirect','Good', \"\n",
    "    \"'Unknown') label \"\n",
    "    \"from enriched_error_codes limit 20;\"\n",
    ")\n",
    "!echo \"$sql\" | \"$ksql\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopping our Docker environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./gradlew --console=plain -q composeDown\n",
    "!/usr/local/bin/docker ps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
